# Utilizing PySpark SQL and Big Data to Analyze Home_Sales

## Description:  
This project helps to determine key facts regarding home sales data using PySpark and Spark SQL on Google Colab. Spark is utilized to create temporary table views,cache and uncache those veiws, and partition and parquet data for quicker querying of the data. Some questions that this project answers are:
* What is the average price for a four bedroom house sold in each year?
* What is the average price of a three bedroom three bathroom house based on the year it was built?
* What is the average price of a three bedroom, three bathroom, two story, 2,000+ sqft house based on the year it was built?
* What is the "view" rating for homes costing more than or equal to $350,000?
* What are the "view" ratings for houses where the average price is greater than or equal to $350,000?

## Technologies  

* python
* PySpark and findspark libraries
* SQL Querying
* Visual Studio Code

## Data Source  
All data used for this challenge comes from the csv found at the following url: https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv"


## Important Documents
* Home_Sales_starter_code_colab.ipynb
* Home_Sales_starter_code.ipynb
 

## Analysis  
My analysis and notes can be found within the ipynb files in this repo. 

## Contributors
In order to complete this challenge I utilized/relied on:
* google searches for query help
* chatGPT to help with error codes where necessary